{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "from tqdm import tqdm\n",
    "# os.chdir(\"./quiztoolbox.com/\")\n",
    "confirmed_questions = set()\n",
    "all_questions = set()\n",
    "question_files = []\n",
    "page_titles = []\n",
    "sitename = \"copyhomework\"\n",
    "for file in glob.glob(\"./\" + sitename + \".com/**/*.html\", recursive=True):\n",
    "    with open(file, 'r') as file_reader:\n",
    "        try:\n",
    "            file_contents = file_reader.read()\n",
    "#             print(file_contents)\n",
    "            if \"show answer\" in file_contents.lower():\n",
    "#                 print(file)\n",
    "                question_files.append(file)\n",
    "        except UnicodeDecodeError:\n",
    "            pass\n",
    "#             print(\"skipping\", file)\n",
    "# display(question_files)\n",
    "print(len(question_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class question():\n",
    "    def __init__(self, text, tag=None):\n",
    "        self.text = text\n",
    "        if tag:\n",
    "            self.tag = tag\n",
    "        else:\n",
    "            self.tag = ''\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        return self.text < other.text\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.text == other.text and self.tag == other.tag\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return self.text.__hash__() + (self.tag.__hash__() if self.tag else 0)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str({'text': self.text, 'tag:': self.tag})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4 import UnicodeDammit\n",
    "import html.parser as hp\n",
    "from collections import Counter\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplictes(lst):\n",
    "    # https://stackoverflow.com/questions/52072381/how-to-print-only-the-duplicate-elements-in-python-list\n",
    "    d =  Counter(lst)  # -> Counter({4: 3, 6: 2, 3: 1, 2: 1, 5: 1, 7: 1, 8: 1})\n",
    "    res = [k for k, v in d.items() if v > 1]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1082/1971 [00:13<00:10, 88.14it/s]"
     ]
    }
   ],
   "source": [
    "for file in tqdm(question_files):\n",
    "#     file = question_files[-3]\n",
    "#     print(file)\n",
    "    with open(file, 'r') as file_reader:\n",
    "    #     file_contents = UnicodeDammit(file_reader.read()).unicode_markup\n",
    "        file_contents = hp.unescape(file_reader.read())\n",
    "\n",
    "    parser = BeautifulSoup(file_contents, \"lxml\")\n",
    "    # print(parser)\n",
    "    tag = parser.find(\"meta\",  property=\"og:description\")\n",
    "    if tag:\n",
    "        tag = tag['content']\n",
    "    headings = parser.find_all(\"div\", class_=\"panel-heading\")\n",
    "    questions = []\n",
    "    for h in headings:\n",
    "        questions.append(question(unidecode.unidecode(h.text).strip(), tag))\n",
    "    #     questions.append(h.get_text())\n",
    "\n",
    "    questions = sorted(questions)\n",
    "    all_questions.update(questions)\n",
    "    found = get_duplictes(questions)\n",
    "#     if len(found)==0:\n",
    "#         print(\"missing questions on \", file)\n",
    "    confirmed_questions.update(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(confirmed_questions))\n",
    "# display(sorted(confirmed_questions))\n",
    "display(sorted(confirmed_questions, key=lambda q:q.tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fake_questions = all_questions.difference(confirmed_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(all_questions))\n",
    "print(len(confirmed_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in confirmed_questions:\n",
    "    if \"honorlock\".lower() in s.text.lower():\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(sitename + '.all_q.txt', 'wb')\n",
    "pickle.dump(all_questions, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(sitename + '.confirmed_q.txt', 'wb')\n",
    "pickle.dump(confirmed_questions, file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
